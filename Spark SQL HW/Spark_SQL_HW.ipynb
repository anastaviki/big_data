{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46de985e-72ae-4e40-8bae-8f1c970f40a5",
   "metadata": {},
   "source": [
    "In this homework we are going to use Jupyter/Databricks Notebooks. Please complete the tasks within one notebook. For each query (SELECT) please prepare 2 different solutions: using dataframe manipulation and Spark SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64585c40-85d7-4bcc-afd2-3ae64cb93393",
   "metadata": {},
   "source": [
    "**TASK 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11e20a16-51b4-4105-a6c3-0bfb655c0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import datetime\n",
    "import os\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import countDistinct, count,  desc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import dense_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d3394e7-fd83-40be-8a98-247ecb945a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark: Dataframes_HW\").config(\"spark.app.name\", \"Spark: Dataframes_HW\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0750e401-bfad-4ebc-8e04-16fc031a3e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[seller_id: int, seller_name: string, daily_target: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|      100000|\n",
      "|        1|   seller_1|       83478|\n",
      "|        2|   seller_2|       94114|\n",
      "|        3|   seller_3|       50299|\n",
      "|        4|   seller_4|       72654|\n",
      "|        5|   seller_5|       28862|\n",
      "|        6|   seller_6|       61878|\n",
      "|        7|   seller_7|       72047|\n",
      "|        8|   seller_8|       54715|\n",
      "|        9|   seller_9|       82824|\n",
      "+---------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "relative_path = os.path.join(current_directory, 'RDD_HW')\n",
    "file_path = relative_path +'/sellers.csv'\n",
    "sellers_rdd = sc.textFile(file_path).map(lambda x: x.split(\",\"))\n",
    "sellers_rdd_header = sellers_rdd.first()\n",
    "sellers_rdd = sellers_rdd.filter(lambda x: x != sellers_rdd_header)\n",
    "sellers_rdd = sellers_rdd.map(lambda x: (int(x[0]), x[1], int(x[2])))\n",
    "schema = StructType([\n",
    "    StructField(\"seller_id\", IntegerType(), True),\n",
    "    StructField(\"seller_name\", StringType(), True),\n",
    "    StructField(\"daily_target\", IntegerType(), True)\n",
    "])\n",
    "sellers_df = spark.createDataFrame(sellers_rdd, schema=schema)\n",
    "display(sellers_df)\n",
    "sellers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dead5636-f40d-4eaf-b058-c4aa39b3c1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product_id: int, product_name: string, price: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         0|   product_0|   22|\n",
      "|         1|   product_1|   35|\n",
      "|         2|   product_2|  146|\n",
      "|         3|   product_3|   17|\n",
      "|         4|   product_4|   66|\n",
      "|         5|   product_5|   31|\n",
      "|         6|   product_6|  127|\n",
      "|         7|   product_7|  116|\n",
      "|         8|   product_8|  121|\n",
      "|         9|   product_9|   98|\n",
      "|        10|  product_10|   54|\n",
      "|        11|  product_11|   25|\n",
      "|        12|  product_12|  125|\n",
      "|        13|  product_13|    8|\n",
      "|        14|  product_14|  100|\n",
      "|        15|  product_15|  111|\n",
      "|        16|  product_16|    1|\n",
      "|        17|  product_17|  115|\n",
      "|        18|  product_18|   69|\n",
      "|        19|  product_19|   59|\n",
      "+----------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = relative_path +'/products.csv'\n",
    "products_rdd = sc.textFile(file_path).map(lambda x: x.split(\",\"))\n",
    "products_rdd_header = products_rdd.first()\n",
    "products_rdd = products_rdd.filter(lambda x: x != products_rdd_header)\n",
    "products_rdd = products_rdd.map(lambda x: (int(x[0]), x[1], int(x[2])))\n",
    "schema = StructType([\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"product_name\", StringType(), True),\n",
    "    StructField(\"price\", IntegerType(), True)\n",
    "])\n",
    "products_df = spark.createDataFrame(products_rdd, schema=schema)\n",
    "display(products_df)\n",
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "acd0cd89-e14c-4cb5-8dea-4d9ba9545f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: int, product_id: int, seller_id: int, date: date, num_pieces_sold: int, bill_raw_text: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|       1|         0|        0|2020-01-07|              5|wmravyotewquljbnw...|\n",
      "|       2|         0|        0|2020-01-06|             14|dctggbxvuwschfvte...|\n",
      "|       3|         0|        0|2020-01-05|             10|zrgfjuaqwsyliyrfm...|\n",
      "|       4|         0|        0|2020-01-08|             71|isnczxkbfrodexqnT...|\n",
      "|       5|         0|        0|2020-01-08|             14|wehgahgpljcinzjhg...|\n",
      "|       6|         0|        0|2020-01-09|             80|yfezqwnlsmprxkeuu...|\n",
      "|       7|         0|        0|2020-01-05|             61|gglhmrggmstqbcxmg...|\n",
      "|       8|         0|        0|2020-01-02|             78|yntlmywelrlhanqmk...|\n",
      "|       9|         0|        0|2020-01-05|             99|hhedtiuedwjosrigz...|\n",
      "|      10|         0|        0|2020-01-10|             14|bfdvbejpojfiuflbl...|\n",
      "|      11|         0|        0|2020-01-09|             95|ysriixkpcipejvzja...|\n",
      "|      12|         0|        0|2020-01-02|             33|aisnmitmapbbvzlqg...|\n",
      "|      13|         0|        0|2020-01-10|             39|jikgofgmgfinjkefg...|\n",
      "|      14|         0|        0|2020-01-04|             85|ffohflpgydrkpvpaf...|\n",
      "|      15|         0|        0|2020-01-04|             42|dbuzmhpmaaumqyibe...|\n",
      "|      16|         0|        0|2020-01-05|             14|sOtfwdcamsjzedycL...|\n",
      "|      17|         0|        0|2020-01-02|             90|cfetaytjzhoizsyml...|\n",
      "|      18|         0|        0|2020-01-05|             45|nynizsquhpatfgaow...|\n",
      "|      19|         0|        0|2020-01-06|             19|fjtiyvnoewzgleywu...|\n",
      "|      20|         0|        0|2020-01-01|             44|rqlXwkpqutlktsyzj...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = relative_path +'/sales.csv'\n",
    "sales_rdd = sc.textFile(file_path).map(lambda x: x.split(\",\"))\n",
    "sales_rdd_header = sales_rdd.first()\n",
    "sales_rdd = sales_rdd.filter(lambda x: x != sales_rdd_header)\n",
    "sales_rdd = sales_rdd.map(lambda x: (\n",
    "    int(x[0]),  \n",
    "    int(x[1]), \n",
    "    int(x[2]),  \n",
    "    x[3],   \n",
    "    int(x[4]),  \n",
    "    x[5]  \n",
    "))\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"seller_id\", IntegerType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"num_pieces_sold\", IntegerType(), True),\n",
    "    StructField(\"bill_raw_text\", StringType(), True)\n",
    "])\n",
    "sales_df = spark.createDataFrame(sales_rdd, schema=schema)\n",
    "sales_df = sales_df.withColumn(\"date\", to_date(sales_df[\"date\"], 'yyyy-mm-dd'))\n",
    "display(sales_df)\n",
    "sales_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c662842-bc33-4146-8dbd-1e7d419fb49e",
   "metadata": {},
   "source": [
    "1.\tPlease create TempViews upon dataframes from previous lesson: products_df, sales_df, sellers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bea96207-703f-412d-ae98-5dc78e08fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.createOrReplaceTempView(\"products\")\n",
    "sales_df.createOrReplaceTempView(\"sales\")\n",
    "sellers_df.createOrReplaceTempView(\"sellers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380149df-8bfa-4ef7-ab5d-7a4c596dbdc3",
   "metadata": {},
   "source": [
    "2.\tSelect number of products sold at least once. Use the TempViews created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab5487c4-bc22-411d-91d4-2e8b94155949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|Number of products sold at least once|\n",
      "+-------------------------------------+\n",
      "|                                86485|\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_products_sold = spark.sql(\"SELECT COUNT(DISTINCT product_id) as `Number of products sold at least once` FROM sales\")\n",
    "num_products_sold.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94262d14-239c-43b6-a392-d5cc1f896b7b",
   "metadata": {},
   "source": [
    "3.\tSelect number of distinct sellers who sold any of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b7fa49c-fdfa-41b0-abfc-91007aa308ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|Number of distinct sellers who sold any of the products|\n",
      "+-------------------------------------------------------+\n",
      "|                                                     10|\n",
      "+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_distinct_sellers = sales_df.select(countDistinct(\"seller_id\").alias(\"Number of distinct sellers who sold any of the products\"))\n",
    "num_distinct_sellers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb586f-c3f4-4c3f-b2f3-88fdf193ed88",
   "metadata": {},
   "source": [
    "4.\tSelect the most popular product (by number of orders) in the sales table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5cfba502-0cb5-4b83-bb5b-60489292b20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular product by number of orders:\n",
      "+----------+----------------+\n",
      "|product_id|Number of orders|\n",
      "+----------+----------------+\n",
      "|         0|         3800000|\n",
      "+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_popular_product = sales_df.groupBy(\"product_id\").agg(count(\"*\").alias(\"Number of orders\")) \\\n",
    "    .orderBy(desc(\"Number of orders\")).limit(1)\n",
    "print(\"Most popular product by number of orders:\")\n",
    "most_popular_product.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc7c14-a298-4191-9323-a1c81a8b28dd",
   "metadata": {},
   "source": [
    "5.\tSelect the number of distinct products has been sold in each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "562fc65d-5f19-411f-8f95-abc150c57fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct products sold in each date:\n",
      "+----------+---------------------------+\n",
      "|      date|Number of distinct products|\n",
      "+----------+---------------------------+\n",
      "|2020-01-01|                      18210|\n",
      "|2020-01-02|                      18305|\n",
      "|2020-01-03|                      17952|\n",
      "|2020-01-04|                      18167|\n",
      "|2020-01-05|                      18386|\n",
      "|2020-01-06|                      17984|\n",
      "|2020-01-07|                      18285|\n",
      "|2020-01-08|                      17892|\n",
      "|2020-01-09|                      18053|\n",
      "|2020-01-10|                      18330|\n",
      "+----------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_products_sold_by_date = sales_df.groupBy(\"date\").agg(countDistinct(\"product_id\").alias(\"Number of distinct products\")) \\\n",
    "    .orderBy(\"date\")\n",
    "print(\"Number of distinct products sold in each date:\")\n",
    "distinct_products_sold_by_date.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2f94d-9970-4691-b473-b761dbe5f466",
   "metadata": {},
   "source": [
    "6.\tSelect all sales made by seller with seller_id=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fe8b51d-2e5f-4811-8c5e-402ca5614aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sales made by seller with seller_id=7:\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|       bill_raw_text|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "|   95016|     10292|        7|2020-01-07|             86|ddjxhepqkpwionxlw...|\n",
      "|   95023|     13642|        7|2020-01-03|              5|hqlmpvnyluuvdxNyl...|\n",
      "|   95042|     54476|        7|2020-01-10|             75|frecsxijhiwsujzuu...|\n",
      "|   95065|     86757|        7|2020-01-04|             95|dxrsOgtaxcxcpulcc...|\n",
      "|   95067|      9749|        7|2020-01-06|             83|unhtoxghdrgvvtemo...|\n",
      "|   95070|     88175|        7|2020-01-09|             32|azfydzqrzsftwhzqy...|\n",
      "|   95075|     36251|        7|2020-01-09|             56|rrezcdybsktrdfuvr...|\n",
      "|   95089|     73423|        7|2020-01-10|             15|noqsnpzdtiobzqqlu...|\n",
      "|   95092|     57982|        7|2020-01-06|             94|tkaviwhjZlzrtviqq...|\n",
      "|   95096|      3694|        7|2020-01-02|             19|wymacbkmqednyybou...|\n",
      "|   95105|     51200|        7|2020-01-08|             54|mjzkjszsyzokbusqr...|\n",
      "|   95112|     96554|        7|2020-01-06|             84|iheixykavfjngybzf...|\n",
      "|   95118|     88483|        7|2020-01-10|             76|bnfalaawuyftzwpvv...|\n",
      "|   95127|     29759|        7|2020-01-07|             84|snpkpcqlubgjwvpax...|\n",
      "|   95128|     68914|        7|2020-01-02|             94|yawuplskokrutoyer...|\n",
      "|   95129|     73927|        7|2020-01-04|             62|ttxamfaapqnoyiyfc...|\n",
      "|   95151|     63000|        7|2020-01-08|             51|kfreekpblnblejxvv...|\n",
      "|   95155|     61577|        7|2020-01-04|            100|zrfskjibcmrbotcyx...|\n",
      "|   95161|     85462|        7|2020-01-02|             51|kyqygdvabiswgyvxa...|\n",
      "|   95164|     95701|        7|2020-01-01|            100|dgvbosbqgrpelnohq...|\n",
      "+--------+----------+---------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_by_seller_7 = sales_df.filter(sales_df.seller_id == 7)\n",
    "print(\"All sales made by seller with seller_id=7:\")\n",
    "sales_by_seller_7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173199fd-e99c-4493-949f-9a04f6d55b9e",
   "metadata": {},
   "source": [
    "7.\tRemove the bill_raw_text column from sales dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "820efdc3-fafb-4685-bd67-8cf124e3be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+---------------+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|\n",
      "+--------+----------+---------+----------+---------------+\n",
      "|       1|         0|        0|2020-01-07|              5|\n",
      "|       2|         0|        0|2020-01-06|             14|\n",
      "|       3|         0|        0|2020-01-05|             10|\n",
      "|       4|         0|        0|2020-01-08|             71|\n",
      "|       5|         0|        0|2020-01-08|             14|\n",
      "|       6|         0|        0|2020-01-09|             80|\n",
      "|       7|         0|        0|2020-01-05|             61|\n",
      "|       8|         0|        0|2020-01-02|             78|\n",
      "|       9|         0|        0|2020-01-05|             99|\n",
      "|      10|         0|        0|2020-01-10|             14|\n",
      "|      11|         0|        0|2020-01-09|             95|\n",
      "|      12|         0|        0|2020-01-02|             33|\n",
      "|      13|         0|        0|2020-01-10|             39|\n",
      "|      14|         0|        0|2020-01-04|             85|\n",
      "|      15|         0|        0|2020-01-04|             42|\n",
      "|      16|         0|        0|2020-01-05|             14|\n",
      "|      17|         0|        0|2020-01-02|             90|\n",
      "|      18|         0|        0|2020-01-05|             45|\n",
      "|      19|         0|        0|2020-01-06|             19|\n",
      "|      20|         0|        0|2020-01-01|             44|\n",
      "+--------+----------+---------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df = sales_df.drop(\"bill_raw_text\")\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f875df4-7b05-4e78-94ce-aac3ba7eb316",
   "metadata": {},
   "source": [
    "8.\tSelect 10 biggest (num_pieces_sold) orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4198520d-9b4c-42a1-9a02-1c54e86da353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 biggest (num_pieces_sold) orders:\n",
      "+--------+----------+---------+----------+---------------+----+\n",
      "|order_id|product_id|seller_id|      date|num_pieces_sold|rank|\n",
      "+--------+----------+---------+----------+---------------+----+\n",
      "|      31|         0|        0|2020-01-07|            100|   1|\n",
      "|      89|         0|        0|2020-01-08|            100|   1|\n",
      "|     106|         0|        0|2020-01-04|            100|   1|\n",
      "|     115|         0|        0|2020-01-02|            100|   1|\n",
      "|     346|         0|        0|2020-01-08|            100|   1|\n",
      "|     378|         0|        0|2020-01-06|            100|   1|\n",
      "|     590|         0|        0|2020-01-07|            100|   1|\n",
      "|     593|         0|        0|2020-01-06|            100|   1|\n",
      "|     595|         0|        0|2020-01-07|            100|   1|\n",
      "|     640|         0|        0|2020-01-03|            100|   1|\n",
      "|     758|         0|        0|2020-01-05|            100|   1|\n",
      "|    1119|         0|        0|2020-01-09|            100|   1|\n",
      "|    1123|         0|        0|2020-01-01|            100|   1|\n",
      "|    1167|         0|        0|2020-01-10|            100|   1|\n",
      "|    1198|         0|        0|2020-01-09|            100|   1|\n",
      "|    1299|         0|        0|2020-01-03|            100|   1|\n",
      "|    1325|         0|        0|2020-01-10|            100|   1|\n",
      "|    1398|         0|        0|2020-01-01|            100|   1|\n",
      "|    1492|         0|        0|2020-01-09|            100|   1|\n",
      "|    1534|         0|        0|2020-01-10|            100|   1|\n",
      "+--------+----------+---------+----------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as we do not have any additional criteria for filtering I desided to use dense rank\n",
    "window_spec = Window.orderBy(sales_df.num_pieces_sold.desc())\n",
    "sales_df = sales_df.withColumn(\"rank\", dense_rank().over(window_spec))\n",
    "top_10_biggest_orders = sales_df.filter(sales_df.rank <= 10)\n",
    "print(\"Top 10 biggest (num_pieces_sold) orders:\")\n",
    "top_10_biggest_orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1fa9f-e356-4105-8385-5afc1fb9b2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
